<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
</head>
<body>

<a href="https://www.youtube.com/watch?v=bO96whMlB8E">https://www.youtube.com/watch?v=bO96whMlB8E</a>

<github-md>
**Introduction** : La présentation traite de la capacité des Large Language Models (LLM) à comprendre et à jouer aux échecs, un sujet méconnu mais fascinant. Thibaut Giraud, alias Monsieur Phi, explore cette question à travers l'exemple des échecs, démontrant que les LLM peuvent aller au-delà de la simple répétition de séquences linguistiques.

**Objectifs** : La présentation vise à démontrer que les LLM sont capables de comprendre et de prédire des séquences complexes, comme les parties d'échecs, contrairement à l'idée reçue qu'ils ne sont que des "perroquets stochastiques".

**Points Clés** :
- Les LLM sont souvent comparés à des perroquets stochastiques, une idée introduite par Emily Bender et ses coautrices, suggérant qu'ils ne font que répéter des séquences linguistiques sans véritable compréhension.
- Thibaut Giraud utilise l'exemple des échecs pour illustrer différents niveaux de compréhension chez les LLM.
- Les LLM peuvent identifier des structures et des patterns de surface dans les séquences de caractères, mais une véritable compréhension nécessite une représentation interne du jeu.
- Des modèles comme GPT-3.5 Turbo Instruct démontrent une capacité surprenante à jouer aux échecs à un niveau élevé (environ 1800 Elo), prouvant qu'ils ne se contentent pas de répéter des séquences mais construisent une représentation interne du jeu.
- Des expériences avec des modèles plus petits, comme celui de Adam Carvonon, confirment que même des LLM de taille modeste peuvent développer une compréhension approfondie des échecs lorsqu'ils sont entraînés sur des données appropriées.

**Méthodologie** : La présentation utilise des exemples concrets et des expériences pour démontrer la capacité des LLM à comprendre et à prédire des séquences complexes. Thibaut Giraud se base sur des études et des tests réalisés avec différents modèles de LLM, notamment GPT-3.5 Turbo Instruct et des modèles plus petits entraînés spécifiquement sur des parties d'échecs.

**Résultats** : Les résultats montrent que les LLM, lorsqu'ils sont entraînés sur des données de parties d'échecs, peuvent développer une représentation interne du jeu et jouer à un niveau élevé. Cela réfute l'idée qu'ils ne sont que des perroquets stochastiques et démontre une forme de compréhension bien au-delà de la simple répétition de séquences linguistiques.

**Conclusion** : La présentation conclut que les LLM sont capables de comprendre et de prédire des séquences complexes, comme les parties d'échecs, en développant une représentation interne du jeu. Cela remet en question l'idée reçue qu'ils ne sont que des perroquets stochastiques et ouvre la voie à une meilleure compréhension de leurs capacités et de leurs limites.
</github-md>
<script src="https://cdn.jsdelivr.net/gh/MarketingPipeline/Markdown-Tag/markdown-tag.js"></script>
</body>